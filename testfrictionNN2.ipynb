{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52314c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import *\n",
    "from equations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbef849",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochADAM = 200000\n",
    "epochLBFGS=100000\n",
    "N_u=100\n",
    "N_f=500\n",
    "seed=1234\n",
    "log_frequency=10000\n",
    "history_frequency=10\n",
    "NLayers=6\n",
    "NNeurons=10\n",
    "noiseLevel=[]\n",
    "weights = [5,3,5,4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6892492",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {}\n",
    "# Data size on the solution u\n",
    "hp[\"N_u\"] = N_u\n",
    "# Collocation points size, where we’ll check for f = 0\n",
    "hp[\"N_f\"] = N_f\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 1-sized output [u]\n",
    "hp[\"layers\"] = [1]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 2-sized output [h, H]\n",
    "hp[\"h_layers\"] = [1]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 1-sized output [C]\n",
    "hp[\"C_layers\"] = [1]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 4-sized input [u,C], \n",
    "#   1-sized output [taub]\n",
    "hp[\"friction_layers\"] = [3]+[NNeurons]*NLayers+[1]\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "hp[\"tf_epochs\"] = epochADAM\n",
    "hp[\"tf_lr\"] = 0.001\n",
    "hp[\"tf_b1\"] = 0.99\n",
    "hp[\"tf_eps\"] = 1e-1\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "hp[\"nt_epochs\"] = epochLBFGS\n",
    "hp[\"log_frequency\"] = log_frequency\n",
    "# Record the history\n",
    "hp[\"save_history\"] = True\n",
    "hp[\"history_frequency\"] = history_frequency\n",
    "# path for loading data and saving models\n",
    "repoPath = \"./\"\n",
    "appDataPath = os.path.join(repoPath, \"matlab_SSA\", \"DATA\")\n",
    "path = os.path.join(appDataPath, \"Helheim_Weertman_iT080_PINN_flowline_CF_2dInv.mat\")\n",
    "\n",
    "loss_weights = [10**(-w) for w in weights]\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# check the input\n",
    "if type(noiseLevel) != list:\n",
    "    noiseLevel = [] # set to no noise\n",
    "\n",
    "if noiseLevel:\n",
    "    modelPath = \"./Models/SSA1D_3NN_\"+str(NLayers)+\"x\"+str(NNeurons)+\"_noise_\" + \"\".join([str(i)+\"_\" for i in noiseLevel])+ \"weights\" + \"\".join([str(w)+\"_\" for w in weights]) + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "else:\n",
    "    modelPath = \"./Models/SSA1D_3NN_\"+str(NLayers)+\"x\"+str(NNeurons)+\"_weights\"+ \"\".join([str(w)+\"_\" for w in weights]) + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "modelPath += (\"_seed_\" + str(seed) if seed else \"\")\n",
    "# + \"ADAM\"+str(hp[\"tf_epochs\"]) +\"_BFGS\"+str(hp[\"nt_epochs\"])\n",
    "reloadModel = False # reload from previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f942ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Exact_vel, X_star, u_star, X_u_train, u_train, X_f, X_bc, u_bc, X_cf, n_cf, xub, xlb, uub, ulb, mu = prep_Helheim_data_flowline(path, hp[\"N_u\"], hp[\"N_f\"]) #}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8fbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSA1D_frictionNN_uhH(SSA1D): #{{{\n",
    "    '''\n",
    "    class of learning friction laws from observed u, H, and h, and PDEs\n",
    "    '''\n",
    "    def __init__(self, hp, logger, X_f, \n",
    "            X_bc, u_bc, X_cf, n_cf, \n",
    "            xub, xlb, uub, ulb, \n",
    "            modelPath, reloadModel,\n",
    "            mu, n=3.0, \n",
    "            loss_weights=[1e-2, 1e-6, 1e-10, 1e-10, 1e-12]):\n",
    "        super().__init__(hp, logger, X_f, \n",
    "                X_bc, u_bc, X_cf, n_cf,\n",
    "                xub, xlb, uub[0:1], ulb[0:1],\n",
    "                modelPath, reloadModel,\n",
    "                mu, loss_weights=loss_weights)\n",
    "        # hp[\"h_layers\"] defines h and H model\n",
    "        self.h_model = create_NN(hp[\"h_layers\"], inputRange=(xlb, xub), outputRange=(ulb[1:3], uub[1:3]))\n",
    "        # hp[\"C_layers\"] defines C model\n",
    "        self.C_model = create_NN(hp[\"C_layers\"], inputRange=(xlb, xub), outputRange=(ulb[3:4], uub[3:4]))\n",
    "\n",
    "        # hp[\"friction_layers\"] defines friction model\n",
    "        fri_lb = (ulb[3:4]**2)*(ulb[0:1]**(1.0/n))\n",
    "        fri_ub = (uub[3:4]**2)*(uub[0:1]**(1.0/n))\n",
    "        \n",
    "        self.friction_model = create_NN(hp[\"friction_layers\"], inputRange=(ulb[0:3], uub[0:3]), outputRange=(fri_lb, fri_ub))\n",
    "        self.trainableLayers = (self.model.layers[1:-1]) + (self.h_model.layers[1:-1]) + (self.friction_model.layers[1:-1])\n",
    "        self.trainableVariables = self.model.trainable_variables + self.h_model.trainable_variables + self.friction_model.trainable_variables\n",
    "\n",
    "    # need to overwrite nn_model, which is used in computing the loss function\n",
    "    @tf.function\n",
    "    def nn_model(self, X):\n",
    "        '''\n",
    "        get the velocity and derivative prediction from the NN\n",
    "        '''\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(X)\n",
    "\n",
    "            u = self.model(X)\n",
    "\n",
    "            hsol = self.h_model(X)\n",
    "            h = hsol[:, 0:1]\n",
    "            H = hsol[:, 1:2]\n",
    "\n",
    "        u_x = tape.gradient(u, X)\n",
    "        del tape\n",
    "\n",
    "        return u, u_x, h, H, 0\n",
    "\n",
    "    @tf.function\n",
    "    def f_model(self):\n",
    "        '''\n",
    "        The actual PINN\n",
    "        '''\n",
    "        # viscosity\n",
    "        mu = self.mu\n",
    "        n = self.n\n",
    "\n",
    "        # Using the new GradientTape paradigm of TF2.0,\n",
    "        # which keeps track of operations to get the gradient at runtime\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Watching the two inputs we’ll need later, x and y\n",
    "            tape.watch(self.x_f)\n",
    "\n",
    "            # just rename the input\n",
    "            X_f = self.x_f\n",
    "\n",
    "            # Getting the prediction\n",
    "            u, u_x, h, H, C = self.nn_model(X_f)\n",
    "\n",
    "            eta = 0.5*mu *(u_x**2+1.0e-30)**(0.5*(1.0-n)/n)\n",
    "            # stress tensor\n",
    "            etaH = eta * H\n",
    "            B11 = etaH*(4*u_x)\n",
    "\n",
    "            # use NN to predict the basal stress\n",
    "            tempX = tf.concat([u, h, H], axis=1)\n",
    "            taub = self.friction_model(tempX) \n",
    "        \n",
    "        # Getting the other derivatives\n",
    "        sigma11 = tape.gradient(B11, self.x_f)\n",
    "\n",
    "        # surface gradient\n",
    "        h_x = tape.gradient(h, self.x_f)\n",
    "\n",
    "        # Letting the tape go\n",
    "        del tape\n",
    "\n",
    "        u_norm = (u**2)**0.5\n",
    "        f1 = sigma11 - taub*u/(u_norm+1e-30) - self.rhoi*self.g*H*h_x\n",
    "        return f1\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def loss(self, uv, X_u):\n",
    "        '''\n",
    "        loss = |u-uobs|+|h-hobs|+|H-Hobs|+|f1|\n",
    "        '''\n",
    "        # match h, H, and C to the training data\n",
    "        u0 = uv[:,0:1]\n",
    "        h0 = uv[:,1:2]\n",
    "        H0 = uv[:,2:3]\n",
    "\n",
    "        u0_pred = self.model(X_u)\n",
    "        hH_pred = self.h_model(X_u)\n",
    "        h0_pred = hH_pred[:,0:1]\n",
    "        H0_pred = hH_pred[:,1:2]\n",
    "\n",
    "        # f_model on the collocation points \n",
    "        f1_pred = self.f_model()\n",
    "        # calving front\n",
    "        fc1_pred = self.cf_model(self.X_cf, self.n_cf)\n",
    "\n",
    "        # velocity misfit\n",
    "        mse_u = self.loss_weights[0]*(self.yts**2) * tf.reduce_mean(tf.square(u0 - u0_pred))\n",
    "        # geometry misfit\n",
    "        mse_h = self.loss_weights[1]*tf.reduce_mean(tf.square(h0 - h0_pred))\n",
    "        mse_H = self.loss_weights[1]*tf.reduce_mean(tf.square(H0 - H0_pred))\n",
    "        # residual of PDE\n",
    "        mse_f1 = self.loss_weights[3]*tf.reduce_mean(tf.square(f1_pred))\n",
    "        # calving front boundary\n",
    "        mse_fc1 = self.loss_weights[4]*tf.reduce_mean(tf.square(fc1_pred))\n",
    "\n",
    "        # sum the total\n",
    "        totalloss = mse_u + mse_h + mse_H + mse_f1 + mse_fc1\n",
    "        return {\"loss\": totalloss, \"mse_u\": mse_u, \"mse_h\": mse_h, \n",
    "                \"mse_H\": mse_H, \"mse_f1\": mse_f1, \"mse_fc1\": mse_fc1} \n",
    "\n",
    "    @tf.function\n",
    "    def test_error(self, X_star, u_star):\n",
    "        '''\n",
    "        test error of taub\n",
    "        '''\n",
    "        u_pred = self.model(X_star)\n",
    "        hH_pred = self.h_model(X_star)\n",
    "        uhH_pred = tf.concat([u_pred, hH_pred], axis=1)\n",
    "        sol_pred = self.friction_model(uhH_pred)\n",
    "        \n",
    "        # ref taub\n",
    "        ref_sol = u_star[:,3:4]**2**(u_star[:,0:1]**(1.0/3.0))\n",
    "        \n",
    "        return  tf.math.reduce_euclidean_norm(tf.math.abs(sol_pred) - tf.math.abs(ref_sol)) / tf.math.reduce_euclidean_norm(ref_sol)\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        '''\n",
    "        return numpy array of the model\n",
    "        '''\n",
    "        u_pred = self.model(X_star)\n",
    "\n",
    "        hH_pred = self.h_model(X_star)\n",
    "        h_pred = hH_pred[:, 0:1]\n",
    "        H_pred = hH_pred[:, 1:2]\n",
    "        C_pred = self.C_model(X_star)\n",
    "\n",
    "        return u_pred.numpy(), h_pred.numpy(), H_pred.numpy(), C_pred.numpy()\n",
    "    \n",
    "    def summary(self):\n",
    "        '''\n",
    "        output all model summaries\n",
    "        '''\n",
    "        return self.model.summary(),self.h_model.summary(), self.C_model.summary(), self.friction_model.summary()\n",
    "\n",
    "    #}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bba20cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "{\n",
      "  \"N_u\": 100,\n",
      "  \"N_f\": 500,\n",
      "  \"layers\": [\n",
      "    1,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"h_layers\": [\n",
      "    1,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    2\n",
      "  ],\n",
      "  \"C_layers\": [\n",
      "    1,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"friction_layers\": [\n",
      "    3,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"tf_epochs\": 200000,\n",
      "  \"tf_lr\": 0.001,\n",
      "  \"tf_b1\": 0.99,\n",
      "  \"tf_eps\": 0.1,\n",
      "  \"nt_epochs\": 100000,\n",
      "  \"log_frequency\": 10000,\n",
      "  \"save_history\": true,\n",
      "  \"history_frequency\": 10\n",
      "}\n",
      "\n",
      "TensorFlow version: 2.4.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(hp)\n",
    "# pinn = SSA1D_3NN_calvingfront_invertC(hp, logger, X_f,\n",
    "pinn = SSA1D_frictionNN_uhH(hp, logger, X_f,\n",
    "        X_bc, u_bc,\n",
    "        X_cf, n_cf,\n",
    "        xub, xlb, uub, ulb,\n",
    "        modelPath, reloadModel,\n",
    "        mu=mu,\n",
    "        loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d15fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # error function for logger\n",
    "    X_u = pinn.tensor(X_star)\n",
    "    u = pinn.tensor(u_star)\n",
    "    def error():\n",
    "        return pinn.test_error(X_u, u)\n",
    "    logger.set_error_fn(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddf1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer (MinmaxSc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "up_scale_layer (UpScaleLayer (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 589\n",
      "Trainable params: 581\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_1 (Minmax (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_1 (UpScaleLay (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 602\n",
      "Trainable params: 592\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_2 (Minmax (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_2 (UpScaleLay (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 589\n",
      "Trainable params: 581\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_3 (Minmax (None, 3)                 8         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_3 (UpScaleLay (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 601\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "(None, None, None, None)\n",
      "[1.e-05 1.e-03 1.e-05 1.e-04 1.e-10]\n",
      "-- Starting Adam optimization --\n",
      "tf_epoch =      0  elapsed = 00:07 (+07.3)  loss = 1.6686e+09  \n",
      "tf_epoch =  10000  elapsed = 01:20 (+13.6)  loss = 2.7679e+03  \n"
     ]
    }
   ],
   "source": [
    "    pinn.fit(X_u_train, u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e96dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    pinn.save()\n",
    "    # plot\n",
    "    plot_1D_solutions_all(pinn, X_f, X_star, u_star, xlb, xub, savePath=modelPath)\n",
    "    # history\n",
    "    plot_log_history(pinn, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bba70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
