{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7724532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import *\n",
    "from equations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b492c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochADAM = 400000\n",
    "epochLBFGS = 0\n",
    "N_u=4000\n",
    "N_H=4000\n",
    "N_f=9000\n",
    "N_C=None\n",
    "N_mu=4000\n",
    "seed=1234\n",
    "log_frequency=10000\n",
    "history_frequency=10\n",
    "NLayers=6\n",
    "NNeurons=40\n",
    "noiseLevel=[]\n",
    "weights = [5,3,5,10,16,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80167a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {}\n",
    "# Data size on the solution u\n",
    "hp[\"N_u\"] = N_u\n",
    "hp[\"N_s\"] = N_u\n",
    "hp[\"N_H\"] = N_H\n",
    "hp[\"N_C\"] = N_C\n",
    "hp[\"N_mu\"] = N_mu\n",
    "# Collocation points size, where weâ€™ll check for f = 0\n",
    "hp[\"N_f\"] = N_f\n",
    "# DeepNN topology (2-sized input [x,y], NLayers hidden layer of NNeurons-width, 1-sized output [u,v]\n",
    "hp[\"layers\"] = [2]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x,y], NLayers hidden layer of NNeurons-width, 2-sized output [h, H]\n",
    "hp[\"h_layers\"] = [2]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x,y], NLayers hidden layer of NNeurons-width, 1-sized output [C]\n",
    "hp[\"C_layers\"] = [2]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (1-sized input [x,y], NLayers hidden layer of NNeurons-width, 1-sized output [C]\n",
    "hp[\"mu_layers\"] = [2]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 4-sized input [u,v,C], \n",
    "#   1-sized output [taub]\n",
    "hp[\"friction_layers\"] = [4]+[NNeurons]*NLayers+[1]\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "hp[\"tf_epochs\"] = epochADAM\n",
    "hp[\"tf_lr\"] = 0.001\n",
    "hp[\"tf_b1\"] = 0.99\n",
    "hp[\"tf_eps\"] = 1e-1\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "hp[\"nt_epochs\"] = epochLBFGS\n",
    "hp[\"log_frequency\"] = log_frequency\n",
    "# Record the history\n",
    "hp[\"save_history\"] = True\n",
    "hp[\"history_frequency\"] = history_frequency\n",
    "\n",
    "# path for loading data and saving models\n",
    "repoPath = \"./\"\n",
    "appDataPath = os.path.join(repoPath, \"matlab_SSA\", \"DATA\")\n",
    "path = os.path.join(appDataPath, \"Helheim_Big_PINN_fastflow_Rignot_SMW_JoughinComposite.mat\")\n",
    "\n",
    "modelPath = './Models/SSA2D_4NN_3NN_6x20_weights5_3_5_8_14_8_20231124_143323'\n",
    "\n",
    "reloadModel = True\n",
    "weights = [5, 3, 5, 10, 16]\n",
    "loss_weights = [10**(-w) for w in weights]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e0dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, Exact_vx, Exact_vy, X_star, u_star, X_u_train, u_train, X_f, X_bc, u_bc, X_cf, n_cf, xub, xlb, uub, ulb, mu = prep_2D_data_withmu(path, N_f=hp[\"N_f\"], N_u=hp[\"N_u\"], N_s=hp[\"N_s\"], N_H=hp[\"N_H\"], N_C=hp[\"N_C\"], N_mu=hp[\"N_mu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74566b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_u_train['H'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842cc8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "{\n",
      "  \"N_u\": 4000,\n",
      "  \"N_s\": 4000,\n",
      "  \"N_H\": 500,\n",
      "  \"N_C\": null,\n",
      "  \"N_mu\": 4000,\n",
      "  \"N_f\": 9000,\n",
      "  \"layers\": [\n",
      "    2,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    2\n",
      "  ],\n",
      "  \"h_layers\": [\n",
      "    2,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    2\n",
      "  ],\n",
      "  \"C_layers\": [\n",
      "    2,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    1\n",
      "  ],\n",
      "  \"mu_layers\": [\n",
      "    2,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    1\n",
      "  ],\n",
      "  \"friction_layers\": [\n",
      "    4,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    40,\n",
      "    1\n",
      "  ],\n",
      "  \"tf_epochs\": 400000,\n",
      "  \"tf_lr\": 0.001,\n",
      "  \"tf_b1\": 0.99,\n",
      "  \"tf_eps\": 0.1,\n",
      "  \"nt_epochs\": 0,\n",
      "  \"log_frequency\": 10000,\n",
      "  \"save_history\": true,\n",
      "  \"history_frequency\": 10\n",
      "}\n",
      "\n",
      "TensorFlow version: 2.4.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ./Models/SSA2D_FlightTrackH_3NN_6x20_weights5_3_5_8_14_20231126_010143/mu_model//{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5ef1a4bd48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pinn = SSA_4NN(hp, logger, X_f,\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mX_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mxub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mulb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreloadModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PINNS/equations/SSA.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hp, logger, X_f, X_cf, n_cf, xub, xlb, uub, ulb, modelPath, reloadModel, mu, n, loss_weights)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/h_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/C_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/mu_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# hp[\"h_layers\"] defines h and H model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./Models/SSA2D_FlightTrackH_3NN_6x20_weights5_3_5_8_14_20231126_010143/mu_model//{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "logger = Logger(hp)\n",
    "pinn = SSA_4NN(hp, logger, X_f,\n",
    "        X_cf, n_cf,\n",
    "        xub, xlb, uub, ulb,\n",
    "        modelPath, reloadModel,\n",
    "        loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f30725",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn.model.layers[-1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn.h_model.layers[-1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    yts = 3600*24*365\n",
    "    X, Y = np.meshgrid(np.linspace(xlb[0],xub[0],200), np.linspace(xlb[1],xub[1], 200))\n",
    "    # obs\n",
    "    ux = yts*griddata(X_star, u_star[:,0].flatten(), (X, Y), method='cubic')\n",
    "    uy = yts*griddata(X_star, u_star[:,1].flatten(), (X, Y), method='cubic')\n",
    "    h_obs = griddata(X_star, u_star[:,2].flatten(), (X, Y), method='cubic')\n",
    "    H_obs = griddata(X_star, u_star[:,3].flatten(), (X, Y), method='cubic')\n",
    "    C_obs = griddata(X_star, u_star[:,4].flatten(), (X, Y), method='cubic')\n",
    "    mu_obs = griddata(X_star, u_star[:,5].flatten(), (X, Y), method='cubic')\n",
    "\n",
    "    # predicted solution\n",
    "    u_pred, v_pred, h, H, C_pred, mu = pinn.predict(X_star)\n",
    "    u_nn = yts*griddata(X_star, u_pred[:,0].flatten(), (X, Y), method='cubic')\n",
    "    v_nn = yts*griddata(X_star, v_pred[:,0].flatten(), (X, Y), method='cubic')\n",
    "    C_nn = griddata(X_star, C_pred[:,0], (X, Y), method='cubic')\n",
    "    h_nn = griddata(X_star, h[:,0], (X, Y), method='cubic')\n",
    "    H_nn = griddata(X_star, H[:,0], (X, Y), method='cubic')\n",
    "    mu_nn = griddata(X_star, mu[:,0], (X, Y), method='cubic')\n",
    "\n",
    "    H_interp = griddata(X_u_train['H'], u_train['H'].flatten(), (X, Y), method='cubic')\n",
    "    C_interp = griddata(X_u_train['C'], u_train['C'].flatten(), (X, Y), method='cubic')\n",
    "    mu_interp = griddata(X_u_train['mu'], u_train['mu'].flatten(), (X, Y), method='cubic')\n",
    "    # residual\n",
    "    f1, f2 = pinn.f_model()\n",
    "    F1 = griddata(X_f, f1[:,0], (X, Y), method='cubic')\n",
    "    F2 = griddata(X_f, f2[:,0], (X, Y), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "    vranges={'vel obs': [0,8e3], 'vel': [0,8e3], 'vel-vel obs':[-1e3,1e3], \n",
    "             'H':[0,1500], 'H obs':[0,1500],'H interp':[0,1500], \n",
    "             'H-H obs':[-0.25e3,0.25e3],'H-H interp':[-0.25e3,0.25e3], \n",
    "             'C':[0,8e3], 'C obs':[0,8e3],'C-C obs':[-2e3,2e3],\n",
    "             'mu':[0.5e8,1.8e8], 'mu obs':[0.5e8,1.8e8],'mu-mu obs':[-1e8, 1e8],\n",
    "             's-s obs':[-100,100], 's':[-500,2000], 's obs':[-500,2000]\n",
    "          }\n",
    "    ###########################\n",
    "    plotData = {}\n",
    "    plotData['vel obs'] = np.sqrt(ux**2+uy**2)\n",
    "    plotData['s obs'] = h_obs\n",
    "    plotData['C obs'] = C_obs\n",
    "    plotData['mu obs'] = mu_obs\n",
    "    plotData['H obs'] = H_obs\n",
    "    ###########################\n",
    "    vel = np.sqrt(u_nn**2+v_nn**2)\n",
    "    plotData['vel'] = vel\n",
    "    plotData['s'] = h_nn\n",
    "    plotData['C'] = np.abs(C_nn)\n",
    "    plotData['mu'] = np.abs(mu_nn)\n",
    "    plotData['H'] = np.abs(H_nn)\n",
    "    ###########################\n",
    "    plotData['vel-vel obs'] =  plotData['vel'] -  plotData['vel obs'] \n",
    "    plotData['s-s obs'] = h_nn - h_obs\n",
    "    plotData['C-C obs'] = plotData['C'] - C_obs\n",
    "    plotData['mu-mu obs'] = plotData['mu'] - C_obs\n",
    "    plotData['H-H obs'] = plotData['H'] - H_obs\n",
    "    ###########################\n",
    "    plotData['H interp'] = H_interp\n",
    "    plotData['H-H interp'] = (H_obs - H_interp)\n",
    "    plotData['C interp'] = C_interp\n",
    "    plotData['Training data'] = 0*H_obs\n",
    "\n",
    "#     flagthin = (vel<2000)\n",
    "#     plotData['H-H interp'][flagthin] = 0\n",
    "#     plotData['H-H obs'][flagthin] = 0\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 5 , figsize=(16,12))\n",
    "\n",
    "    for ax,name in zip(axs.ravel(), plotData.keys()):\n",
    "        vr = vranges.setdefault(name, [None, None])\n",
    "        im = ax.imshow(plotData[name], interpolation='nearest', cmap='rainbow',\n",
    "                extent=[X.min(), X.max(), Y.min(), Y.max()],\n",
    "                vmin=vr[0], vmax=vr[1],\n",
    "                origin='lower', aspect='auto')\n",
    "        ax.set_title(name)\n",
    "        fig.colorbar(im, ax=ax, shrink=1)\n",
    "        if name =='Training data':\n",
    "            ax.scatter(X_u_train['H'][:,0:1],X_u_train['H'][:,1:2],1,'black')\n",
    "            ax.scatter(X_u_train['C'][:,0:1],X_u_train['C'][:,1:2],1,'red')\n",
    "            ax.set_xlim(X.min(), X.max())\n",
    "            ax.set_ylim(Y.min(), Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cea3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7872b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
