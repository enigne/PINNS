{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625ef735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 17:27:06.098310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 17:27:06.223706: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-20 17:27:06.227059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /totten_1/chenggong/trunk-jpl/externalpackages/netcdf/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/petsc/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/hdf5/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/proj/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/gdal/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/triangle/install/lib:/totten_1/chenggong/Elmer/install/lib:\n",
      "2023-10-20 17:27:06.227070: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-20 17:27:06.842337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /totten_1/chenggong/trunk-jpl/externalpackages/netcdf/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/petsc/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/hdf5/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/proj/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/gdal/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/triangle/install/lib:/totten_1/chenggong/Elmer/install/lib:\n",
      "2023-10-20 17:27:06.842415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /totten_1/chenggong/trunk-jpl/externalpackages/netcdf/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/petsc/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/hdf5/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/proj/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/gdal/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/triangle/install/lib:/totten_1/chenggong/Elmer/install/lib:\n",
      "2023-10-20 17:27:06.842420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import *\n",
    "from equations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c872bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochADAM = 1000\n",
    "epochLBFGS=0\n",
    "N_u=50\n",
    "N_f=100\n",
    "seed=1234\n",
    "log_frequency=10000\n",
    "history_frequency=10\n",
    "NLayers=6\n",
    "NNeurons=10\n",
    "noiseLevel=[]\n",
    "# vel, (h,H), C, FSSA, (FH, SMB), BC\n",
    "weights = [5,3,5,8,1,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5aafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {}\n",
    "# Data size on the solution u\n",
    "hp[\"N_u\"] = N_u\n",
    "# Collocation points size, where weâ€™ll check for f = 0\n",
    "hp[\"N_f\"] = N_f\n",
    "# DeepNN topology (2-sized input [x,t], NLayers hidden layer of NNeurons-width, 1-sized output [u]\n",
    "hp[\"layers\"] = [2]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (2-sized input [x,t], NLayers hidden layer of NNeurons-width, 2-sized output [h, H]\n",
    "hp[\"h_layers\"] = [2]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 1-sized output [C]\n",
    "hp[\"C_layers\"] = [1]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (2-sized input [x,t], NLayers hidden layer of NNeurons-width, 1-sized output [SMB]\n",
    "hp[\"smb_layers\"] = [2]+[NNeurons]*NLayers+[1]\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "hp[\"tf_epochs\"] = epochADAM\n",
    "hp[\"tf_lr\"] = 0.001\n",
    "hp[\"tf_b1\"] = 0.99\n",
    "hp[\"tf_eps\"] = 1e-1\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "hp[\"nt_epochs\"] = epochLBFGS\n",
    "hp[\"log_frequency\"] = log_frequency\n",
    "# Record the history\n",
    "hp[\"save_history\"] = True\n",
    "hp[\"history_frequency\"] = history_frequency\n",
    "# path for loading data and saving models\n",
    "repoPath = \"./\"\n",
    "appDataPath = os.path.join(repoPath, \"matlab_SSA\", \"DATA\")\n",
    "path = os.path.join(appDataPath, \"Helheim_Big_Rignot_SMW_Schoof_PINN_flowline_transient.mat\")\n",
    "\n",
    "loss_weights = [10**(-w) for w in weights]\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "modelPath = \"./Models/SSA1D_transient_\"+str(NLayers)+\"x\"+str(NNeurons)+\"_weights\"+ \"\".join([str(w)+\"_\" for w in weights]) + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "modelPath += (\"_seed_\" + str(seed) if seed else \"\")\n",
    "# + \"ADAM\"+str(hp[\"tf_epochs\"]) +\"_BFGS\"+str(hp[\"nt_epochs\"])\n",
    "reloadModel = False # reload from previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star, u_star, X_train, u_train, X_1d, C_1d, X_f, X_bc, u_bc, X_cf, n_cf, xub, xlb, uub, ulb, mu = prep_Helheim_transient(path=path, N_u=N_u, N_f=N_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77338a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "{\n",
      "  \"N_u\": 50,\n",
      "  \"N_f\": 100,\n",
      "  \"layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"h_layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    2\n",
      "  ],\n",
      "  \"C_layers\": [\n",
      "    1,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"smb_layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"tf_epochs\": 1000,\n",
      "  \"tf_lr\": 0.001,\n",
      "  \"tf_b1\": 0.99,\n",
      "  \"tf_eps\": 0.1,\n",
      "  \"nt_epochs\": 0,\n",
      "  \"log_frequency\": 10000,\n",
      "  \"save_history\": true,\n",
      "  \"history_frequency\": 10\n",
      "}\n",
      "\n",
      "TensorFlow version: 2.11.0\n",
      "Eager execution: True\n",
      "GPU-accerelated: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 17:27:08.119423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /totten_1/chenggong/trunk-jpl/externalpackages/netcdf/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/petsc/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/hdf5/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/proj/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/gdal/install/lib:/totten_1/chenggong/trunk-jpl/externalpackages/triangle/install/lib:/totten_1/chenggong/Elmer/install/lib:\n",
      "2023-10-20 17:27:08.119441: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-20 17:27:08.119456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (totten): /proc/driver/nvidia/version does not exist\n",
      "2023-10-20 17:27:08.120590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(hp)\n",
    "pinn = SSA1D_transient(hp, logger, X_f,\n",
    "        X_bc, u_bc,\n",
    "        X_cf, n_cf,\n",
    "        xub, xlb, uub, ulb,\n",
    "        modelPath, reloadModel,\n",
    "        mu=mu,\n",
    "        loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c714c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error function for logger\n",
    "X_u = pinn.tensor(X_1d)\n",
    "u = pinn.tensor(C_1d)\n",
    "def error():\n",
    "    return pinn.test_error(X_u, u)\n",
    "logger.set_error_fn(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd852510",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " minmax_scale_layer (MinmaxS  (None, 2)                6         \n",
      " caleLayer)                                                      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " up_scale_layer (UpScaleLaye  (None, 1)                4         \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 591\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " minmax_scale_layer_1 (Minma  (None, 2)                6         \n",
      " xScaleLayer)                                                    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                30        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      " up_scale_layer_1 (UpScaleLa  (None, 2)                6         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 614\n",
      "Trainable params: 602\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " minmax_scale_layer_2 (Minma  (None, 1)                4         \n",
      " xScaleLayer)                                                    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " up_scale_layer_2 (UpScaleLa  (None, 1)                4         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 589\n",
      "Trainable params: 581\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " minmax_scale_layer_3 (Minma  (None, 2)                6         \n",
      " xScaleLayer)                                                    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                30        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " up_scale_layer_3 (UpScaleLa  (None, 1)                4         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 591\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "(None, None, None, None)\n",
      "[1.e-05 1.e-03 1.e-05 1.e-08 1.e-01 1.e-14]\n",
      "-- Starting Adam optimization --\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/totten_1/chenggong/PINNs/utils/neuralnetwork.py\", line 219, in Adam_optimization_step  *\n        loss_value, grads = self.grad(X_u, u)\n    File \"/totten_1/chenggong/PINNs/utils/neuralnetwork.py\", line 119, in grad  *\n        loss_value = self.loss(u, X)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 193, in loss  *\n        fc1_pred = self.cf_model(self.X_cf, self.n_cf)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 150, in cf_model  *\n        u, s, H, C, smb, u_x, H_x, H_t = self.nn_model(X)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 69, in nn_model  *\n        x = X[:, 0:1]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_DOUBLE, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=0](X, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [200], [2], [2], [2] and with computed input tensors: input[3] = <1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/totten_1/chenggong/PINNs/utils/neuralnetwork.py:235\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X_u, u)\u001b[0m\n\u001b[1;32m    232\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(u)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Optimizing\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# use LBFGS\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLBFGS_optimization(X_u, u)\n",
      "File \u001b[0;32m/totten_1/chenggong/PINNs/utils/neuralnetwork.py:211\u001b[0m, in \u001b[0;36mNeuralNetwork.Adam_optimization\u001b[0;34m(self, X_u, u)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_train_opt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_epochs):\n\u001b[0;32m--> 211\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam_optimization_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_train_epoch(epoch, loss_value)\n",
      "File \u001b[0;32m/totten_1/chenggong/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_vs3hkec.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__Adam_optimization_step\u001b[0;34m(self, X_u, u)\u001b[0m\n\u001b[1;32m     11\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 13\u001b[0m (loss_value, grads) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mgrad, (ag__\u001b[38;5;241m.\u001b[39mld(X_u), ag__\u001b[38;5;241m.\u001b[39mld(u)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtf_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(grads), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mwrap_training_variables, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileh1gcmife.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__grad\u001b[0;34m(self, X, u)\u001b[0m\n\u001b[1;32m     12\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 14\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss, (ag__\u001b[38;5;241m.\u001b[39mld(u), ag__\u001b[38;5;241m.\u001b[39mld(X)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss_value)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mwrap_training_variables, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filex2opheri.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__loss\u001b[0;34m(self, uv, X_u)\u001b[0m\n\u001b[1;32m     21\u001b[0m smb_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msmb_model, (ag__\u001b[38;5;241m.\u001b[39mld(X_u),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     22\u001b[0m (fSSA_pred, fH_pred) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mf_model, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 23\u001b[0m fc1_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcf_model, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mX_cf, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mn_cf), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     24\u001b[0m mse_u \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39myts \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msquare, (ag__\u001b[38;5;241m.\u001b[39mld(u0) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(u_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     25\u001b[0m mse_s \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_weights[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msquare, (ag__\u001b[38;5;241m.\u001b[39mld(s0) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(s_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file4l0l62m2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__cf_model\u001b[0;34m(self, X, nn)\u001b[0m\n\u001b[1;32m     13\u001b[0m mu \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmu\n\u001b[1;32m     14\u001b[0m n \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mn\n\u001b[0;32m---> 15\u001b[0m (u, s, H, C, smb, u_x, H_x, H_t) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnn_model, (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m base \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(s) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(H)\n\u001b[1;32m     17\u001b[0m eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(mu) \u001b[38;5;241m*\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mld(u_x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-30\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(n)) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(n))\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file4uaih6jo.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__nn_model\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(X)[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m t \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(X)[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/totten_1/chenggong/PINNs/utils/neuralnetwork.py\", line 219, in Adam_optimization_step  *\n        loss_value, grads = self.grad(X_u, u)\n    File \"/totten_1/chenggong/PINNs/utils/neuralnetwork.py\", line 119, in grad  *\n        loss_value = self.loss(u, X)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 193, in loss  *\n        fc1_pred = self.cf_model(self.X_cf, self.n_cf)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 150, in cf_model  *\n        u, s, H, C, smb, u_x, H_x, H_t = self.nn_model(X)\n    File \"/totten_1/chenggong/PINNs/equations/SSA1D_transient.py\", line 69, in nn_model  *\n        x = X[:, 0:1]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_DOUBLE, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=0](X, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [200], [2], [2], [2] and with computed input tensors: input[3] = <1 1>.\n"
     ]
    }
   ],
   "source": [
    "pinn.fit(X_train, u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d663e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_log_history(pinn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4068ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinn.save()\n",
    "# # plot\n",
    "# plot_1D_solutions_all(pinn, X_f, X_star, u_star, xlb, xub, savePath=modelPath)\n",
    "# # history\n",
    "# plot_log_history(pinn, modelPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
