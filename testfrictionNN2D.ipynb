{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84599fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import *\n",
    "from equations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c21710",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochADAM = 400000\n",
    "epochLBFGS = 0\n",
    "N_u=2000\n",
    "N_f=4000\n",
    "seed=1234\n",
    "log_frequency=10000\n",
    "history_frequency=10\n",
    "NLayers=6\n",
    "NNeurons=10\n",
    "noiseLevel=[]\n",
    "weights = [5,3,5,8,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef23e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {}\n",
    "# Data size on the solution u\n",
    "hp[\"N_u\"] = N_u\n",
    "# Collocation points size, where weâ€™ll check for f = 0\n",
    "hp[\"N_f\"] = N_f\n",
    "# DeepNN topology (2-sized input [x,y], NLayers hidden layer of NNeurons-width, 1-sized output [u,v]\n",
    "hp[\"layers\"] = [2]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x,y], NLayers hidden layer of NNeurons-width, 2-sized output [h, H]\n",
    "hp[\"h_layers\"] = [2]+[NNeurons]*NLayers+[2]\n",
    "# DeepNN topology (1-sized input [x,y], NLayers hidden layer of NNeurons-width, 1-sized output [C]\n",
    "hp[\"C_layers\"] = [2]+[NNeurons]*NLayers+[1]\n",
    "# DeepNN topology (1-sized input [x], NLayers hidden layer of NNeurons-width, 4-sized input [u,v,C], \n",
    "#   1-sized output [taub]\n",
    "hp[\"friction_layers\"] = [3]+[NNeurons]*NLayers+[1]\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "hp[\"tf_epochs\"] = epochADAM\n",
    "hp[\"tf_lr\"] = 0.001\n",
    "hp[\"tf_b1\"] = 0.99\n",
    "hp[\"tf_eps\"] = 1e-1\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "hp[\"nt_epochs\"] = epochLBFGS\n",
    "hp[\"log_frequency\"] = log_frequency\n",
    "# Record the history\n",
    "hp[\"save_history\"] = True\n",
    "hp[\"history_frequency\"] = history_frequency\n",
    "# path for loading data and saving models\n",
    "repoPath = \"./\"\n",
    "appDataPath = os.path.join(repoPath, \"matlab_SSA\", \"DATA\")\n",
    "path = os.path.join(appDataPath, \"Helheim_Weertman_iT080_PINN_fastflow_CF.mat\")\n",
    "\n",
    "loss_weights = [10**(-w) for w in weights]\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# check the input\n",
    "if type(noiseLevel) != list:\n",
    "    noiseLevel = [] # set to no noise\n",
    "\n",
    "if noiseLevel:\n",
    "    modelPath = \"./Models/SSA2D_3NN_\"+str(NLayers)+\"x\"+str(NNeurons)+\"_noise_\" + \"\".join([str(i)+\"_\" for i in noiseLevel])+ \"weights\" + \"\".join([str(w)+\"_\" for w in weights]) + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "else:\n",
    "    modelPath = \"./Models/SSA2D_3NN_\"+str(NLayers)+\"x\"+str(NNeurons)+\"_weights\"+ \"\".join([str(w)+\"_\" for w in weights]) + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "modelPath += (\"_seed_\" + str(seed) if seed else \"\")\n",
    "# + \"ADAM\"+str(hp[\"tf_epochs\"]) +\"_BFGS\"+str(hp[\"nt_epochs\"])\n",
    "reloadModel = False # reload from previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01995c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, Exact_vx, Exact_vy, X_star, u_star, X_u_train, u_train, X_f, X_bc, u_bc, X_cf, n_cf, xub, xlb, uub, ulb, mu = prep_Helheim_data_all(path, hp[\"N_u\"], hp[\"N_f\"]) #}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a06a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "{\n",
      "  \"N_u\": 2000,\n",
      "  \"N_f\": 4000,\n",
      "  \"layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    2\n",
      "  ],\n",
      "  \"h_layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    2\n",
      "  ],\n",
      "  \"C_layers\": [\n",
      "    2,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"friction_layers\": [\n",
      "    3,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    10,\n",
      "    1\n",
      "  ],\n",
      "  \"tf_epochs\": 400000,\n",
      "  \"tf_lr\": 0.001,\n",
      "  \"tf_b1\": 0.99,\n",
      "  \"tf_eps\": 0.1,\n",
      "  \"nt_epochs\": 0,\n",
      "  \"log_frequency\": 10000,\n",
      "  \"save_history\": true,\n",
      "  \"history_frequency\": 10\n",
      "}\n",
      "\n",
      "TensorFlow version: 2.4.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(hp)\n",
    "pinn = SSA2D_frictionNN(hp, logger, X_f,\n",
    "        X_bc, u_bc,\n",
    "        X_cf, n_cf,\n",
    "        xub, xlb, uub, ulb,\n",
    "        modelPath, reloadModel,\n",
    "        mu=mu,\n",
    "        loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644baf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error function for logger\n",
    "X_u = pinn.tensor(X_star)\n",
    "u = pinn.tensor(u_star)\n",
    "def error():\n",
    "    return pinn.test_error(X_u, u)\n",
    "logger.set_error_fn(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16baaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer (MinmaxSc (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "up_scale_layer (UpScaleLayer (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 614\n",
      "Trainable params: 602\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_1 (Minmax (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_1 (UpScaleLay (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 614\n",
      "Trainable params: 602\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_2 (Minmax (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_2 (UpScaleLay (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 591\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "minmax_scale_layer_3 (Minmax (None, 3)                 8         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "up_scale_layer_3 (UpScaleLay (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 601\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "(None, None, None, None)\n",
      "[1.e-05 1.e-03 1.e-05 1.e-08 1.e-14]\n",
      "-- Starting Adam optimization --\n",
      "tf_epoch =      0  elapsed = 00:21 (+21.5)  loss = 3.9141e+04  \n",
      "tf_epoch =  10000  elapsed = 06:45 (+24.2)  loss = 4.5797e+01  \n",
      "tf_epoch =  20000  elapsed = 13:09 (+23.9)  loss = 1.9884e+01  \n",
      "tf_epoch =  30000  elapsed = 19:31 (+21.5)  loss = 1.5378e+01  \n",
      "tf_epoch =  40000  elapsed = 25:53 (+22.1)  loss = 1.3508e+01  \n",
      "tf_epoch =  50000  elapsed = 32:14 (+20.6)  loss = 1.2417e+01  \n",
      "tf_epoch =  60000  elapsed = 38:35 (+21.0)  loss = 1.1645e+01  \n",
      "tf_epoch =  70000  elapsed = 44:55 (+20.2)  loss = 1.0972e+01  \n",
      "tf_epoch =  80000  elapsed = 51:16 (+21.2)  loss = 1.0303e+01  \n",
      "tf_epoch =  90000  elapsed = 57:37 (+21.1)  loss = 9.7968e+00  \n",
      "tf_epoch = 100000  elapsed = 03:58 (+21.1)  loss = 9.3776e+00  \n",
      "tf_epoch = 110000  elapsed = 10:20 (+21.9)  loss = 9.0637e+00  \n",
      "tf_epoch = 120000  elapsed = 16:41 (+20.6)  loss = 8.7677e+00  \n",
      "tf_epoch = 130000  elapsed = 23:05 (+24.2)  loss = 8.4710e+00  \n",
      "tf_epoch = 140000  elapsed = 29:26 (+20.9)  loss = 8.2875e+00  \n",
      "tf_epoch = 150000  elapsed = 35:51 (+24.7)  loss = 8.0965e+00  \n",
      "tf_epoch = 160000  elapsed = 42:11 (+20.0)  loss = 8.0069e+00  \n",
      "tf_epoch = 170000  elapsed = 48:33 (+21.6)  loss = 7.8594e+00  \n",
      "tf_epoch = 180000  elapsed = 54:54 (+21.2)  loss = 7.7215e+00  \n"
     ]
    }
   ],
   "source": [
    "pinn.fit(X_u_train, u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3932c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn.save()\n",
    "# plot\n",
    "plot_2D_solutions_all(pinn, X_f, X_star, u_star, xlb, xub, \n",
    "                      vranges={'u - u obs': [-1e3,1e3], 'v - v obs': [-1e3,1e3], \n",
    "                               'h - h obs': [-1e2,1e2], 'H - H obs': [-1e2,1e2], \n",
    "                               'C - C obs': [-1e3,1e3]}, savePath=modelPath)\n",
    "# history\n",
    "plot_log_history(pinn, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece35331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
